## Лабораторная работа №4

### Задание 1

Заполните массив 500 простыми числами, написанными слитно. Используя каждый изученный алгоритм поиска подстрок (наивный, Рабина-Карпа, Бойера-Мура, Кнута-Морриса-Пратта), посчитайте количество наиболее часто встречающихся двузначных чисел в образовавшейся строке. Сравните изученные алгоритмы поиска подстрок. Сделайте вывод о их достоинствах и недостатках.

#### Создание массива из 500 простых чисел

```
# Функция для проверки, является ли число простым
def is_prime(n):
    if n <= 1:
        return False
    for i in range(2, int(n**0.5)+1):
        if n % i == 0:
            return False
    return True

# Создаем массив из 500 простых чисел, записанных слитно
primes = []
num = 2
while len(primes) < 500:
    if is_prime(num):
        primes.append(num)
    num += 1
prime_str = "".join(str(p) for p in primes)

# Инициализируем словарь для хранения количества двузначных чисел
counts = {}
for i in range(len(prime_str)-1):
    num = int(prime_str[i:i+2])
    if 10 <= num <= 99:
        if num in counts:
            counts[num] += 1
        else:
            counts[num] = 1
```

#### Наивный алгоритм

```
max_count = 0
max_num = None
for num, count in counts.items():
    if count > max_count:
        max_count = count
        max_num = num
print(f"Наиболее часто встречающееся двузначное число - {max_num}, встречается {max_count} раз(а).")
```

#### Алгоритм Рабина-Карпа

```
max_count = 0
max_num = None
for num, count in counts.items():
    pattern = str(num)
    pattern_len = len(pattern)
    text_len = len(prime_str)
    pattern_hash = hash(pattern)
    text_hash = hash(prime_str[:pattern_len])
    for i in range(text_len - pattern_len + 1):
        if pattern_hash == text_hash and prime_str[i:i+pattern_len] == pattern:
            if count > max_count:
                max_count = count
                max_num = num
            break
        if i < text_len - pattern_len:
            text_hash = hash(prime_str[i+1:i+1+pattern_len])
print(f"Наиболее часто встречающееся двузначное число - {max_num}, встречается {max_count} раз(а).")
```

#### Алгоритм Бойера-Мура

```
max_count = 0
max_num = None
for num, count in counts.items():
    pattern = str(num)
    pattern_len = len(pattern)
    last_occurrence = {pattern[i]: i for i in range(pattern_len)}
    i = pattern_len - 1
    while i < len(prime_str):
        if prime_str[i] == pattern[pattern_len-1]:
            k = pattern_len - 2
            j = i - 1
            while k >= 0 and prime_str[j] == pattern[k]:
                j -= 1
                k -= 1
            if k == -1:
                if count > max_count:
                    max_count = count
                    max_num = num
                break
        if i == len(prime_str) - 1:
            break
        skip = pattern_len - last_occurrence.get(prime_str[i], -1) - 1
        i += skip
print(f"Наиболее часто встречающееся двузначное число - {max_num}, встречается {max_count} раз(а).")
```

#### Алгоритм Кнута-Морриса-Пратта

```
max_count = 0
max_num = None
for num, count in counts.items():
    pattern = str(num)
    pattern_len = len(pattern)
    prefix_table = [0] * pattern_len
    j = 0
    for i in range(1, pattern_len):
        while j > 0 and pattern[i] != pattern[j]:
            j = prefix_table[j-1]
        if pattern[i] == pattern[j]:
            j += 1
        prefix_table[i] = j
    j = 0
    for i in range(len(prime_str)):
        while j > 0 and prime_str[i] != pattern[j]:
            j = prefix_table[j-1]
        if prime_str[i] == pattern[j]:
            j += 1
        if j == pattern_len:
            if count > max_count:
                max_count = count
                max_num = num
            break

print("Наиболее часто встречающееся двузначное число:", max_num)
print("Количество вхождений:", max_count)
```

### Сравнение алгоритмов

Сравнение алгоритмов для поиска подстрок (наивный, Рабина-Карпа, Бойера-Мура, Кнута-Морриса-Пратта)

#### Наивный алгоритм

Самый простой способ поиска подстроки в строке. Он основан на сравнении каждого символа подстроки с символами строки в последовательном порядке. Если символы совпадают, алгоритм переходит к следующему символу подстроки, иначе он переходит к следующему символу в строке. Алгоритм продолжает этот процесс до тех пор, пока не будет найдено полное совпадение подстроки.

###### Достоинства:

* Простота и легкость реализации
* Хорошо работает на коротких строках и подстроках

###### Недостатки:

* Низкая производительность на длинных строках и подстроках, так как количество сравнений символов может быть очень большим
* Асимптотическая сложность $O(n \cdot m)$, где $n$ - длина строки, $m$ - длина подстроки

#### Алгоритм Рабина-Карпа

Алгоритм Рабина-Карпа использует хеширование для поиска подстроки в строке. Алгоритм вычисляет хеш-функцию для подстроки и сравнивает ее с хеш-функцией каждого фрагмента строки. Если хеш-функции совпадают, алгоритм проверяет полное совпадение символов. Если совпадение не найдено, алгоритм переходит к следующему фрагменту строки и снова вычисляет хеш-функцию.

###### Достоинства:

* Эффективность алгоритма не зависит от расположения подстроки в строке
* Основан на быстром вычислении хеш-функций, что ускоряет поиск
* Сложность алгоритма в худшем случае $O(n+m)$, где $n$ - длина строки, $m$ - длина подстроки

###### Недостатки:

* Возможны коллизии в хеш-функциях, что может привести к ложным совпадениям
* Дополнительная сложность при вычислении хеш-функции

#### Алгоритм Бойера-Мура

Алгоритм Бойера-Мура основан на использовании двух таблиц: таблицы суффиксов и таблицы смещений. Таблица суффиксов содержит информацию о правильных суффиксах подстроки, а таблица смещений содержит информацию о максимальном смещении для каждого символа в подстроке. Алгоритм начинает сравнение с конца подстроки и строки, и если символы не совпадают, он использует таблицу смещений для определения максимально возможного смещения и переходит на него. Если совпадение не найдено, алгоритм сдвигает подстроку на максимально возможное смещение и повторяет процесс.

###### Достоинства:

* Эффективен на длинных строках и подстроках
* Использует таблицы суффиксов и смещений, что ускоряет поиск и делает его более эффективным
* Лучшая сложность в среднем случае $O(n/m)$, где $n$ - длина строки, $m$ - длина подстроки

###### Недостатки:

* Реализация более сложная, чем у наивного алгоритма
* Некоторые таблицы могут быть большими и занимать много памяти

#### Алгоритм Кнута-Морриса-Пратта

Алгоритм Кнута-Морриса-Пратта использует префикс-функцию для поиска подстроки в строке. Префикс-функция для подстроки - это массив, содержащий значения наибольшей длины собственного префикса, который является также суффиксом этой подстроки. Алгоритм переходит от начала строки к концу, сравнивая символы подстроки с символами строки. Если символы не совпадают, алгоритм использует префикс-функцию, чтобы определить максимальное смещение и переходит на него. Если совпадение не найдено, алгоритм продолжает поиск.

###### Достоинства:

* Эффективен на длинных строках и подстроках
* Использует префикс-функцию, что делает поиск быстрым и эффективным
* Лучшая сложность в худшем случае $O(n+m)$, где $n$ - длина строки, $m$ - длина подстроки

###### Недостатки:

* Реализация более сложная, чем у наивного алгоритма
* Некоторые вычисления могут быть затратными, если длина подстроки очень большая

### Задание 2

Дан набор рефератов. Выберите любой алгоритм поиска и определите количество плагиата (в % от общего количества символов в реферате) в тексте реферата, взяв за основу соответствующие статьи из Википедии (название файла = название статьи). За плагиат считать любые 3 совпавших слова, идущих подряд. Обоснуйте выбранный алгоритм поиска.

#### Решение

```
from methods import KMP
import wikipedia
import pypandoc

def delcp(x):
    arr = ",<>.[]?!/*&^%$@()_-=+:;"
    for i in arr:
        x = x.replace(i, ' ')
    while "  " in x:
        x = x.replace("  ", " ")
    return x

def get_unique_trigrams(text):
    text = delcp(text.lower())
    words = text.split()
    unique_trigrams = []
    for i in range(len(words) - 2):
        trigram = (words[i], words[i+1], words[i+2])
        if trigram not in unique_trigrams:
            unique_trigrams.append(trigram)
    return unique_trigrams

# Преобразовать текст из docx в txt
essay = pypandoc.convert_file('Улыбка.docx', 'plain').lower()
essay = delcp(essay)

# Получите уникальные триграммы в эссе
mainset = get_unique_trigrams(essay)

wikipedia.set_lang("ru")
origin = wikipedia.page("Улыбка").content.lower()
origin = delcp(origin)

# Получите уникальные триграммы в содержимом страницы Википедии
patternset = get_unique_trigrams(origin)

# Вычислить словарь вхождений триграмм и количество символов
trigram_dict = {}
for pattern in patternset:
    trigram = ' '.join(pattern)
    trigram_dict[trigram] = (KMP(mainset, pattern) * len(trigram), len(pattern[0]) + 1, len(pattern[1]) + 1, len(pattern[2]))

k = 0
dict_values = list(trigram_dict.values())
last = dict_values[0]
k = last[0]

# Исключить случай, когда "ABCD" считается плагиатом "ABC" и "BCD".
for j in range(1, len(dict_values)):
    if last[0] != 0:
        k += (dict_values[j][0] - (last[1] + last[2] + 1))
    else:
        k += dict_values[j][0]
    last = dict_values[j]

plagiarism_percentage = k / len(essay) * 100
print(plagiarism_percentage, "%")
```

### Защита работы

Дана строка A и подстрока B. Используя алгоритм Рабина-Карпа, изменив метод хэширования на один из базовых, удалить все коллизии из строки A и вывести её.

#### Решение

```
def remove_collisions(A, B):
    n = len(A)
    m = len(B)
    
    # Функция для вычисления хэша подстроки
    def compute_hash(string):
        p = 31  # Простое число для хэширования
        m = 10**9 + 9  # Большое простое число для взятия остатка
        hash_value = 0
        p_pow = 1
        for char in string:
            hash_value = (hash_value + (ord(char) - ord('a') + 1) * p_pow) % m
            p_pow = (p_pow * p) % m
        return hash_value
    
    # Вычисляем хэш подстроки B
    hash_B = compute_hash(B)
    
    # Инициализируем переменные
    result = []
    current_hash = compute_hash(A[:m])
    
    # Проверяем первое окно
    if current_hash == hash_B:
        result.append(A[:m])
    
    # Сдвигаем окно по строке A и проверяем остальные подстроки
    for i in range(1, n-m+1):
        # Вычисляем хэш текущего окна, используя предыдущий хэш
        current_hash = (current_hash - (ord(A[i-1]) - ord('a') + 1)) % m
        current_hash = (current_hash * p) % m
        current_hash = (current_hash + (ord(A[i+m-1]) - ord('a') + 1)) % m
        
        # Проверяем текущее окно на коллизию с хэшем подстроки B
        if current_hash == hash_B:
            result.append(A[i:i+m])
    
    # Объединяем все неколлизионные подстроки в одну строку
    return ''.join(result)

# Пример использования
A = "abracadabra"
B = "abra"

result = remove_collisions(A, B)
print(result) 
```

> В этой программе используется алгоритм Рабина-Карпа для поиска коллизий между строкой A и подстрокой B. Мы вычисляем хэш для подстроки B и сравниваем его с хэшами всех окон длины m в строке A. Если хэши совпадают, то текущее окно является коллизией. Мы сохраняем все неколлизионные подстроки в список result и затем объединяем их в одну строку.